Key Ideas
- Cluster/Node - environment in which K8S orchestrates everything
- Pod - container within a node running it's own containers (applications, sql server, etc)

Key Commands
- kubectl -> base command upon which we'll build our k8s commands
- 'kubectl get deployments' (get list of deployments that K8S will attempt to keep running)
- 'kubectl apply -f {deploymentfile}'
- 'kubectl delete deployment {deploymentName}'
- 'kubectl get services' (same idea, services like clusterIPs and nginx loadbalancers)
- 'kubectl delete service {serviceName}'

1) Create a deployment file for our platform service (deploy it to a POD)
- filename: platforms-depl.yaml
- defines the images, cluster IPs, etc needed to setup inside this Pod

2) create the deployment in K8s -> move to this directory and run "kubectl apply -f .\platforms-depl.yaml"
- this creates the pod in k8s, which will spin up, then you can view using "kubectl get deployments"
- REMEMBER: the pod is a container itself and runs your app

3) next we'll create a node port into the node so we can access our pod(s) inside the node/cluster -> "kubectl apply -f .\platforms-np-srv.yaml'
- this creates the service in K8S
- verify it's running using 'kubectl get services'

4) create deployment in k8s for commandSrv

5) create clusteredIP on both platform and commands service so they can communicate w/ each other's POD from within the K8S node

6) create an nginx controller using below command (using as our API Gateway) - 
kubectl apply -f https://raw.githubusercontent.com/kubernetes/ingress-nginx/controller-v1.12.0-beta.0/deploy/static/provider/cloud/deploy.yaml 

7) setup a routing file for nginx to (ingress-srv.yaml)
- this will be our api gateway so we can use a single hostname (acme.com) and, based on endpoint, nginx will forward it to the correct server

8) next setup the persistent volume claim (PVC)
- storage that SQL Server will use inside k8s
- file for deploying this: local-pvc.yaml (kubectl apply -f local-pvc.yaml)
- setup prior to SQL server so we can tell SQLSrv name of PVC to use for storage

9) Create SQL Server SA Pw secret in K8S (reference using db-user-pass name)
- kubectl create secret generic db-user-pass --from-literal=SA_PASSWORD='pa55w0rd!'

10) Create sql server instance, cluster IP for it inside the node, then a load balancer so we can access it from outside K8S in SSMS 
- kubectl apply -f mssql-plat-depl.yaml
- will take a few minutes for the pod to get started and run
- connection notes from ssms:
    - use ssms w/ localhost:1433, use sa & pw as auth 
    - remember to stop any existing local sql server instances or it will interfere w/ this 
    - check "trust server cert" on ssms login screen or it won't allow the connection

11) Setup platform service when in production (appsettings.prod) to use sqlServer as data source
- see program.cs in platformservice

12) Setup rabbitMQ message bus in K8S (platformSrv will publish to the queue, CommandsSrv will consume this and create a matching platform in it's db)
- rabbitmq-depl.yaml 
- once applied, go to http://localhost:15672/, login as guest (pw: guest)

REMEMBER: ClusteredIPs are used to give your apps a port mapping at the POD level (8080 inside pod, 8080 outside in the node/cluster)
REMEMBER: LoadBalancers are used to give you a port into the cluster which you can then map to your PODs ClusteredIPs

13) PlatformService will publish to rabbitMQ, CommandService will subscribe to it (to get new platforms)

14) Last thing, setup gRPC between PlatformSrv and CommandSrv so on startup of commandSrv, it can reach out to PlatformSrv and get all existing platforms to drop in it's database
- REMEMBER: when testing locally, you need to run the server w/ https profile using command -> dotnet run --launch-profile https
- That will expose the https route on the server side, make sure that port matches on the client side config 